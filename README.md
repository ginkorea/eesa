# ğŸ§  EESA: Ensemble-Based Explainable Sentiment Analysis

> A hybrid NLP/ML/LLM framework for transparent, scalable sentiment classification â€” powered by XGBoost, GPT, and custom NLP pipelines.

---

## ğŸ” Overview

**EESA** integrates traditional machine learning pipelines with modern LLMs like GPT-4 to create explainable, auditable sentiment classifiers. It builds upon the **XSXGBoost** algorithm from the original research and augments it with:

- âœ… Few-shot GPT-based explainability scoring
- âœ… Ensemble boosting via XGBoost and weak classifiers
- âœ… A modular, CLI-controlled architecture
- âœ… Full pipeline serialization and inference
- âœ… Support for real-world datasets like Amazon, Yelp, and IMDB

---

## ğŸ“ Directory Structure

```
eesa/
â”œâ”€â”€ eesa.py                 # CLI entry point
â”œâ”€â”€ pipeline.py             # Core sklearn pipeline logic
â”œâ”€â”€ preprocessing/          # Tokenization, vectorization, LLM injectors
â”œâ”€â”€ ensemble/               # XGBoost, GPT Classifier, Weak Models, ANOVA
â”œâ”€â”€ openai_llm/             # GPT-based scoring and summarization
â”œâ”€â”€ labeled_data/           # LLM-labeled versions of datasets
â”œâ”€â”€ results/                # Training outputs, graphs, analysis CSVs
â”œâ”€â”€ data/                   # Raw datasets (.csv, STS, IMDb, etc.)
â”œâ”€â”€ util.py                 # Logging, color printing, helpers
â””â”€â”€ README.md               # You're reading this!
```

---

## ğŸ”§ Installation

```bash
git clone https://github.com/ginkorea/eesa.git
cd eesa
python3 -m venv .eesa_venv
source .eesa_venv/bin/activate
pip install -r requirements.txt
```

### ğŸ“Œ OpenAI API Key

Set your key via:

```bash
export OPENAI_API_KEY=sk-xxx
```

Or use a `.env` file.

---

## ğŸš€ Quickstart

### ğŸ§  Train an Ensemble Model

```bash
python eesa.py train data/gold.csv gold_model --llm --weak --depth 5 --save_dir results
```

- Uses GPT + weak classifiers + XGBoost
- Saves: `results/gold_model_pipeline.pkl` & `gold_model_xgb_model.pkl`

### ğŸª„ Label a Dataset (with GPT)

```bash
python eesa.py label data/gold.csv 100 0
```

- Labels rows 0â€“99 with GPT and outputs `labeled_data/gold_labeled.csv`

### ğŸ“Š Compare Weak Classifiers (ANOVA)

```bash
python eesa.py compare labeled_data/gold_labeled.csv
```

- Compares NB, SVM, RF, and LR with cross-validation & ANOVA

### ğŸ”® Predict with Trained Model

```bash
python eesa.py infer results/gold_model_pipeline.pkl data/gold.csv --output_path results/predictions.csv
```

- Adds `prediction` column to your data

---

## ğŸ§  Methodology

**XSXGBoost + GPT** uses:

- âœ… `XV = [Sentiment Score, Confidence, Explanation Quality]` from GPT
- âœ… Injected as features into XGBoost
- âœ… Explanations stored and graded by GPT

All classification includes a 4-part GPT response:
```
Sentiment Score | Confidence | Explanation Quality | Explanation Text
```

Few-shot examples are included to increase output consistency.

---

## ğŸ“Š Datasets Used

- ğŸ›ï¸ Amazon
- ğŸ¥ IMDB
- ğŸ½ï¸ Yelp
- ğŸ¦ STS-Gold (Stanford Twitter Sentiment)
- ğŸï¸ Movie Review v2.0

Located in the `data/` folder.

---

## ğŸ“– Original Research

- ğŸ§¾ [Gompert: Explainable Sentiment Analysis (PDF)](https://github.com/ginkorea/eesa/blob/main/research/gompert_paper.pdf)
- ğŸ“Š [Slides: Explainable Sentiment Analysis via GPT (PPTX)](https://github.com/ginkorea/eesa/blob/main/research/Gompert_AML_v2.pptx)

Published as part of advanced machine learning work at Johns Hopkins University.

---

## ğŸ›  Future Work

- [ ] Dash frontend for model exploration
- [ ] LLM benchmarking and output auditing tools
- [ ] Multilingual sentiment support
- [ ] Semi-supervised LLM pre-labeling from web data

---

## ğŸ“„ License

MIT License Â© 2023 Joshua Gompert

---

## ğŸ“£ Citation

If you use this repo for your own work:

```
@software{gompert2023eesa,
  author = {Josh Gompert},
  title = {EESA: Ensemble-Based Explainable Sentiment Analysis},
  year = {2023},
  url = {https://github.com/ginkorea/eesa}
}
```
